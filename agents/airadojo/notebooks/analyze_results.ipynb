{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0c8378",
   "metadata": {},
   "source": [
    "# Basic Tools to Analyze Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00003720",
   "metadata": {},
   "source": [
    "In this notebook, we will introduce you to the basic tools for analyzing the results of your experiments. We will examine the outcomes from AIRA<sub>GREEDY</sub>, AIDE<sub>GREEDY</sub>, AIRA<sub>MCTS</sub>, and AIRA<sub>EVO</sub>. You can find the commands to run these experiments in the [README.md](../README.md) under the \"Example Usage\" subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59492a99",
   "metadata": {},
   "source": [
    "## Load Exeriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a715af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sl2998/.conda/envs/aira-dojo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[2025-12-01 12:24:02,411] [_client.py:1025] HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from dojo.utils.environment import get_log_dir\n",
    "from dojo.analysis_utils.meta_data_wrangling import (\n",
    "    collect_all_meta_experiments_in_one_df,\n",
    "    format_experiment_data,\n",
    "    filter_dataframe_based_on_data_validity,\n",
    "    add_node_elapsed_from_first\n",
    ")\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections.abc import Iterable\n",
    "\n",
    "user = os.getenv(\"USER\")\n",
    "\n",
    "\n",
    "def extract_best_node_content(row):\n",
    "    best_idx = row['best_node_idx']\n",
    "    if pd.isna(best_idx):\n",
    "        return row\n",
    "    return row.apply(\n",
    "        lambda x: x[int(best_idx)] if isinstance(x, Iterable) and not isinstance(x, str) and int(best_idx) < len(x) else x\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f1d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictonary with paths to meta-experiments and their corresponding methods (for methods, you can choose any name you like)\n",
    "methods = {\n",
    "    f\"{get_log_dir()}/aira-dojo/user_{user}_issue_AIDE_GREEDY_o3\": \"AIDE_GREEDY\",\n",
    "    f\"{get_log_dir()}/aira-dojo/user_{user}_issue_AIRA_GREEDY_o3\": \"AIRA_GREEDY\",\n",
    "    f\"{get_log_dir()}/aira-dojo/user_{user}_issue_AIRA_EVO_o3\": \"AIRA_EVO\",\n",
    "    f\"{get_log_dir()}/aira-dojo/user_{user}_issue_AIRA_GREEDY_o3\": \"AIRA_MCTS(c=0.25)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea05570d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/gpfs/PLI/sl2998/aira-dojo/logs/aira-dojo/user_sl2998_issue_AIDE_GREEDY_o3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mcollect_all_meta_experiments_in_one_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta_experiment_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_to_method_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m df = filter_dataframe_based_on_data_validity(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/PLI/sl2998/workspace/aira-dojo-fork/src/dojo/analysis_utils/meta_data_wrangling.py:996\u001b[39m, in \u001b[36mcollect_all_meta_experiments_in_one_df\u001b[39m\u001b[34m(meta_experiment_paths, path_to_method_name, max_steps_cap, regenerate_trees, seconds_cutoff, max_processes)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    990\u001b[39m \u001b[33;03mPerforms Phase A: Processing meta experiments to generate trees.\u001b[39;00m\n\u001b[32m    991\u001b[39m \u001b[33;03mPerforms Phase B: Gathers meta experiments data.\u001b[39;00m\n\u001b[32m    992\u001b[39m \u001b[33;03mPerforms Phase C: Processing each experiment to pad the series and\u001b[39;00m\n\u001b[32m    993\u001b[39m \u001b[33;03m    build data frame with one row per experiment.\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# Phase A: Process all the files to generate trees\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m \u001b[43mprocess_all_meta_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_experiment_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregenerate_trees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseconds_cutoff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[38;5;66;03m# Phase B: Gather all the tree data\u001b[39;00m\n\u001b[32m    999\u001b[39m all_experiments, all_keys, overall_max_steps = gather_all_meta_experiment_data(\n\u001b[32m   1000\u001b[39m     meta_experiment_paths,\n\u001b[32m   1001\u001b[39m     path_to_method_name,\n\u001b[32m   1002\u001b[39m     max_steps_cap=max_steps_cap,\n\u001b[32m   1003\u001b[39m     max_processes=max_processes,\n\u001b[32m   1004\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/PLI/sl2998/workspace/aira-dojo-fork/src/dojo/analysis_utils/meta_data_wrangling.py:812\u001b[39m, in \u001b[36mprocess_all_meta_experiments\u001b[39m\u001b[34m(meta_experiment_paths, regenerate_trees, max_processes, seconds_cutoff)\u001b[39m\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m meta_exp \u001b[38;5;129;01min\u001b[39;00m meta_experiment_paths:\n\u001b[32m    811\u001b[39m     meta_path = Path(meta_exp)\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_meta_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    813\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping invalid meta path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    814\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/PLI/sl2998/workspace/aira-dojo-fork/src/dojo/utils/experiment_logs.py:31\u001b[39m, in \u001b[36mis_meta_experiment\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mis_meta_experiment\u001b[39m(path: Union[Path, \u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    Check if the given file path is a meta-experiment directory.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    A meta-experiment directory contains multiple experiment directories.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/PLI/sl2998/workspace/aira-dojo-fork/src/dojo/utils/experiment_logs.py:31\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mis_meta_experiment\u001b[39m(path: Union[Path, \u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    Check if the given file path is a meta-experiment directory.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    A meta-experiment directory contains multiple experiment directories.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m\u001b[43m(\u001b[49m\u001b[43mis_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/aira-dojo/lib/python3.12/pathlib.py:1057\u001b[39m, in \u001b[36mPath.iterdir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1052\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Yield path objects of the directory contents.\u001b[39;00m\n\u001b[32m   1053\u001b[39m \n\u001b[32m   1054\u001b[39m \u001b[33;03m    The children are yielded in arbitrary order, and the\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[33;03m    special entries '.' and '..' are not included.\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m   1058\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_child_relpath(name)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/scratch/gpfs/PLI/sl2998/aira-dojo/logs/aira-dojo/user_sl2998_issue_AIDE_GREEDY_o3'"
     ]
    }
   ],
   "source": [
    "df = collect_all_meta_experiments_in_one_df(\n",
    "    meta_experiment_paths=list(methods.keys()),\n",
    "    path_to_method_name=methods,\n",
    ")\n",
    "df = filter_dataframe_based_on_data_validity(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f833d30",
   "metadata": {},
   "source": [
    "## Getting Statistics from the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b979e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_node_elapsed_from_first(df)\n",
    "statistics_df , _ = format_experiment_data(df, select_using_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d987b7",
   "metadata": {},
   "source": [
    "### Best Node based on Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13906013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"best_node_idx\"] = statistics_df[\"expected_return_node\"]\n",
    "df.apply(extract_best_node_content, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf77d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aira-dojo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
